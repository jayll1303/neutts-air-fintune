# NeuTTS-Air Vietnamese Finetuning

Huáº¥n luyá»‡n mÃ´ hÃ¬nh Text-to-Speech NeuTTS-Air cho tiáº¿ng Viá»‡t.

## âœ¨ Features

- âœ… **Pre-encoding dataset** - Nhanh gáº¥p 10x so vá»›i on-the-fly encoding
- âœ… **Speed optimizations** - TF32, Fused AdamW, dataloader prefetch
- âœ… **Memory efficient** - On-the-fly preprocessing, khÃ´ng trÃ n RAM
- âœ… **Vietnamese phonemizer** - Tá»± Ä‘á»™ng chuyá»ƒn text sang phonemes
- âœ… **Easy inference** - CLI vÃ  quick test script

## ğŸ“‹ Requirements

```bash
pip install torch transformers datasets neucodec phonemizer librosa soundfile fire omegaconf loguru pandas soe-vinorm
```

**CÃ i Ä‘áº·t espeak-ng** (cho phonemizer):

```bash
# Ubuntu/Debian
sudo apt-get install espeak-ng

# macOS
brew install espeak-ng

# Windows: Download tá»« https://github.com/espeak-ng/espeak-ng/releases
```

**ViNorm** - Vietnamese text normalization:
- Tá»± Ä‘á»™ng chuáº©n hÃ³a text tiáº¿ng Viá»‡t (sá»‘, ngÃ y thÃ¡ng, tá»« viáº¿t táº¯t, etc.)
- Cáº£i thiá»‡n cháº¥t lÆ°á»£ng TTS
- TÃ¹y chá»n: Náº¿u khÃ´ng cÃ i, text sáº½ khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a

## ğŸš€ Quick Start

### 1. Chuáº©n bá»‹ Dataset

Tá»• chá»©c dataset theo cáº¥u trÃºc:

```
dataset/
â”œâ”€â”€ metadata.csv          # File chá»©a danh sÃ¡ch audio vÃ  transcript
â””â”€â”€ wavs/                 # ThÆ° má»¥c chá»©a audio files
    â”œâ”€â”€ audio_001.wav
    â”œâ”€â”€ audio_002.wav
    â””â”€â”€ ...
```

**Format `metadata.csv`:**

```csv
audio|transcript
audio_001.wav|Xin chÃ o Viá»‡t Nam
audio_002.wav|ÄÃ¢y lÃ  mÃ´ hÃ¬nh text to speech
audio_003.wav|ChÃºng tÃ´i Ä‘ang huáº¥n luyá»‡n mÃ´ hÃ¬nh
```

**LÆ°u Ã½:**
- Delimiter: `|` (pipe)
- KhÃ´ng cÃ³ header row
- Audio files: WAV format, mono
- Text: Tiáº¿ng Viá»‡t cÃ³ dáº¥u

### 2. Pre-encode Dataset (Khuyáº¿n nghá»‹!)

Pre-encode toÃ n bá»™ dataset 1 láº§n Ä‘á»ƒ training nhanh gáº¥p 10x:

```bash
python prepare_vietnamese_dataset.py \
    --metadata "/mnt/d/tts_dataset_all/metadata.csv" \
    --audio_dir "/mnt/d/tts_dataset_all/wavs" \
    --output "/mnt/d/tts_dataset_all/vietnamese_dataset.pkl" \
    --device "cuda" \
    --batch_size 40
```

**Thá»i gian:** ~36-40 giá» cho 2.6M samples (cháº¡y qua Ä‘Ãªm)  
**Output:** File `vietnamese_dataset.pkl` (~10-20GB)

### 3. Cáº¥u hÃ¬nh Training

Sá»­a `finetune_vietnamese_config.yaml`:

```yaml
# Dataset
dataset_path: "/mnt/d/tts_dataset/vietnamese_dataset.pkl"  # Pre-encoded dataset

# Training
per_device_train_batch_size: 4
gradient_accumulation_steps: 2
num_train_epochs: 3
save_steps: 5000
eval_steps: 10000

# Speed optimizations
tf32: true                       # GPU Ampere+ (RTX 30xx/40xx, A100)
dataloader_pin_memory: true
dataloader_prefetch_factor: 2
```

### 4. Training

```bash
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

**Output:**

```
============================================================
FINETUNING NEUTTS-AIR FOR VIETNAMESE
============================================================

[1/6] Loading config...
[2/6] Loading model... âœ“ 552M parameters
[3/6] Initializing Vietnamese phonemizer... âœ“
[4/6] Loading dataset... âœ“ 2,604,620 samples
[5/6] Preprocessing... âœ“
[6/7] Splitting... âœ“ Train: 2,591,598 | Val: 13,023
[7/7] Setting up training...
  âœ“ TF32 enabled for faster training

============================================================
STARTING TRAINING
============================================================
Batch size: 4 | Accumulation: 2 | Effective: 8
Estimated time: ~2.5-3 ngÃ y (3 epochs)

Step 100: loss=2.456
Step 5000: loss=1.987 | Checkpoint saved
...
```

### 5. Inference

**Quick test:**

```bash
python quick_infer.py
```

**CLI vá»›i custom text:**

```bash
python infer_vietnamese.py \
    --text "Xin chÃ o, Ä‘Ã¢y lÃ  giá»ng nÃ³i tiáº¿ng Viá»‡t" \
    --ref_audio "reference.wav" \
    --ref_text "Text cá»§a reference audio" \
    --output "output.wav" \
    --checkpoint "./checkpoints/neutts-vietnamese/checkpoint-50000"
```

## ğŸ“ Dataset Organization

### Cáº¥u trÃºc ThÆ° má»¥c

```
your-project/
â”œâ”€â”€ finetune_vietnamese.py
â”œâ”€â”€ finetune_vietnamese_config.yaml
â”œâ”€â”€ prepare_vietnamese_dataset.py
â”œâ”€â”€ infer_vietnamese.py
â”œâ”€â”€ quick_infer.py
â”‚
â”œâ”€â”€ dataset/                      # Dataset gá»‘c
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â””â”€â”€ wavs/
â”‚       â”œâ”€â”€ audio_001.wav
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ vietnamese_dataset.pkl        # Pre-encoded dataset
â”‚
â””â”€â”€ checkpoints/                  # Training checkpoints
    â””â”€â”€ neutts-vietnamese/
        â”œâ”€â”€ checkpoint-5000/
        â”œâ”€â”€ checkpoint-10000/
        â””â”€â”€ ...
```

### Format Metadata

**Chuáº©n (khuyáº¿n nghá»‹):**

```csv
audio|transcript
file001.wav|CÃ¢u vÄƒn tiáº¿ng Viá»‡t thá»© nháº¥t
file002.wav|CÃ¢u vÄƒn tiáº¿ng Viá»‡t thá»© hai
```

**Hoáº·c vá»›i Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§:**

```csv
audio|transcript
/full/path/to/file001.wav|CÃ¢u vÄƒn tiáº¿ng Viá»‡t thá»© nháº¥t
/full/path/to/file002.wav|CÃ¢u vÄƒn tiáº¿ng Viá»‡t thá»© hai
```

### YÃªu cáº§u Audio

- **Format:** WAV (PCM)
- **Sample rate:** 16kHz (khuyáº¿n nghá»‹) hoáº·c 24kHz
- **Channels:** Mono (1 channel)
- **Bit depth:** 16-bit
- **Duration:** 1-30 giÃ¢y (tá»‘i Æ°u: 3-10 giÃ¢y)

**Convert audio:**

```bash
# DÃ¹ng ffmpeg
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```

## âš™ï¸ Configuration

### Training Parameters

```yaml
# Model
restore_from: "neuphonic/neutts-air"
codebook_size: 65536
max_seq_len: 2048

# Dataset
dataset_path: "vietnamese_dataset.pkl"  # hoáº·c "metadata.csv"
max_samples: null                       # null = dÃ¹ng táº¥t cáº£

# Training
per_device_train_batch_size: 4          # Batch size per GPU
gradient_accumulation_steps: 2          # Effective batch = 4 * 2 = 8
num_train_epochs: 3                     # Sá»‘ epochs
lr: 0.00004                             # Learning rate
warmup_ratio: 0.05                      # Warmup 5% steps

# Checkpointing
save_steps: 5000                        # Save má»—i 5000 steps
eval_steps: 10000                       # Eval má»—i 10000 steps
save_root: "./checkpoints"
run_name: "neutts-vietnamese"

# Speed optimizations
tf32: true                              # TF32 cho GPU Ampere+
gradient_checkpointing: false           # Báº­t náº¿u OOM
torch_compile: false                    # PyTorch 2.0 compile
dataloader_pin_memory: true
dataloader_prefetch_factor: 2
```

### GPU Memory Requirements

| Batch Size | Gradient Acc | Effective Batch | VRAM | Speed |
|------------|--------------|-----------------|------|-------|
| 1 | 8 | 8 | ~12GB | Cháº­m |
| 2 | 4 | 8 | ~16GB | Trung bÃ¬nh |
| 4 | 2 | 8 | ~22GB | Nhanh (khuyáº¿n nghá»‹) |
| 8 | 1 | 8 | ~40GB | Ráº¥t nhanh (A100) |

**Náº¿u CUDA OOM:**

```yaml
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
gradient_checkpointing: true  # Tiáº¿t kiá»‡m VRAM ~40%
```

## ğŸ¯ Training Workflow

### Workflow Äáº§y Ä‘á»§

```
1. Chuáº©n bá»‹ dataset
   â”œâ”€â”€ Táº¡o metadata.csv
   â”œâ”€â”€ Chuáº©n bá»‹ audio files (WAV, 16kHz, mono)
   â””â”€â”€ Kiá»ƒm tra format

2. Pre-encode dataset (1 láº§n duy nháº¥t)
   â””â”€â”€ python prepare_vietnamese_dataset.py
       â†’ vietnamese_dataset.pkl (~36-40 giá»)

3. Cáº¥u hÃ¬nh training
   â””â”€â”€ Sá»­a finetune_vietnamese_config.yaml

4. Training
   â””â”€â”€ python finetune_vietnamese.py config.yaml
       â†’ checkpoints/ (~2.5-3 ngÃ y cho 3 epochs)

5. Inference
   â”œâ”€â”€ python quick_infer.py (test nhanh)
   â””â”€â”€ python infer_vietnamese.py (full CLI)
```

### Training Time Estimates

**GPU: RTX 3090 (24GB)**

| Mode | Time/batch | 3 epochs (2.6M samples) |
|------|------------|-------------------------|
| On-the-fly encoding | 8.5s | ~30 ngÃ y |
| Pre-encoded | 0.8s | ~5 ngÃ y |
| **Pre-encoded + Optimized** | **0.45s** | **~2.5-3 ngÃ y** |

**GPU: A100 (40GB)**

| Mode | Time/batch | 3 epochs |
|------|------------|----------|
| Pre-encoded + Optimized | 0.35s | ~2.2 ngÃ y |

## ğŸ”§ Troubleshooting

### CUDA Out of Memory

```yaml
# Giáº£m batch size
per_device_train_batch_size: 2
gradient_accumulation_steps: 4

# Báº­t gradient checkpointing
gradient_checkpointing: true
```

### RAM Overflow (Killed)

Code Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u Ä‘á»ƒ khÃ´ng trÃ n RAM. Náº¿u váº«n gáº·p váº¥n Ä‘á»:

```yaml
# Giáº£m dataloader workers
dataloader_num_workers: 2  # Thay vÃ¬ 4
```

### Pre-encoding quÃ¡ cháº­m

```bash
# DÃ¹ng CPU náº¿u GPU báº­n
python prepare_vietnamese_dataset.py --device cpu
```

### Phonemizer Error

```bash
# CÃ i Ä‘áº·t láº¡i espeak-ng
sudo apt-get install --reinstall espeak-ng

# Kiá»ƒm tra
espeak-ng --voices=vi
```

### Training quÃ¡ cháº­m

1. Kiá»ƒm tra GPU utilization: `nvidia-smi`
2. Äáº£m báº£o dÃ¹ng pre-encoded dataset
3. Báº­t TF32: `tf32: true`
4. TÄƒng batch size náº¿u GPU Ä‘á»§ máº¡nh

## ğŸ“Š Performance Benchmarks

### Speedup Summary

```
Baseline (on-the-fly):     30 ngÃ y  (1.0x)
Pre-encoded:               5 ngÃ y   (6.0x faster)
Pre-encoded + Optimized:   2.8 ngÃ y (10.7x faster) â­
```

### Optimizations Applied

- âœ… Pre-encoded dataset (6x)
- âœ… TF32 precision (1.2x)
- âœ… Fused AdamW (1.1x)
- âœ… Dataloader optimizations (1.15x)
- âœ… Increased batch size (1.3x)
- âœ… Reduced eval frequency (1.05x)

**Total:** ~10.7x faster!

## ğŸ“ Example Usage

### Training vá»›i Custom Dataset

```bash
# 1. Pre-encode
python prepare_vietnamese_dataset.py \
    --metadata "my_data/metadata.csv" \
    --audio_dir "my_data/wavs" \
    --output "my_dataset.pkl"

# 2. Sá»­a config
# dataset_path: "my_dataset.pkl"

# 3. Train
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

### Inference vá»›i Checkpoint Cá»¥ thá»ƒ

```bash
python infer_vietnamese.py \
    --text "ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i Viá»‡t Nam" \
    --ref_audio "samples/reference.wav" \
    --ref_text "ÄÃ¢y lÃ  giá»ng tham chiáº¿u" \
    --output "greeting.wav" \
    --checkpoint "./checkpoints/neutts-vietnamese/checkpoint-50000" \
    --temperature 0.7 \
    --top_k 50
```

### Push to Hugging Face

Upload latest checkpoint:

```bash
python push_to_huggingface.py \
    --repo-id YOUR_USERNAME/neutts-vietnamese \
    --token YOUR_HF_TOKEN
```

Upload a specific checkpoint:

```bash
python push_to_huggingface.py \
    --repo-id YOUR_USERNAME/neutts-vietnamese \
    --token YOUR_HF_TOKEN \
    --checkpoint checkpoint-50000
```

Upload ALL checkpoints (each in its own subfolder):

```bash
python push_to_huggingface.py \
    --repo-id YOUR_USERNAME/neutts-vietnamese \
    --token YOUR_HF_TOKEN \
    --all
```

By default, it will push to private repo, to push to public repo, add `--public` flag.

```bash
python push_to_huggingface.py \
    --repo-id YOUR_USERNAME/neutts-vietnamese \
    --token YOUR_HF_TOKEN \
    --public
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is based on [NeuTTS-Air](https://github.com/neuphonic/neutts-air) by Neuphonic.

## ğŸ™ Acknowledgments

- [Neuphonic](https://github.com/neuphonic) for NeuTTS-Air model
- [espeak-ng](https://github.com/espeak-ng/espeak-ng) for Vietnamese phonemization
- Vietnamese TTS community

---

**Happy training!** ğŸš€

For issues or questions, please open an issue on GitHub.
